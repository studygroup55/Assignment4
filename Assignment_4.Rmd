---
title: "Assignment_4_Eva"
author: "Eva Sahlholdt"
date: "2023-05-02"
output: html_document
---

```{r}
pacman::p_load("furrr", "purrr", "tidyverse", "tictoc", "R.utils", "cmdstanr", "rstan", "posterior", "brms")

```

**Create data** 

```{r}

#Define number of featues
n <- 5

#Define possible combinations of features
combinations <- sapply(strsplit(intToBin(0:(2 ^ n - 1)), split = ""), paste0, collapse = "")

#Create empty lists for stimulus and features
stimulus <- list()
arms = list()
spots = list()
legs = list()
eyes = list()
color = list()

k = 0

#Loop through combinations
for (i in combinations){
  k = k + 1
  stimulus = append(stimulus, k)
  arms = append(arms, substr(i, 1,1))
  spots = append(spots, substr(i, 2,2))
  legs = append(legs, substr(i, 3,3))
  eyes = append(eyes, substr(i, 4,4))
  color = append(color, substr(i, 5,5))
}


#Convert to dataframe
data = data.frame(stimulus_number = unlist(stimulus), arms = unlist(arms), spots = unlist(spots), legs = unlist(legs), eyes = unlist(eyes), color = unlist(color))

#Create the category (danger = 1, no danger = 0) depending on certain features
data <- data %>%
  mutate(danger = ifelse(spots == 1 & eyes == 1, 1, 0), 
         stimulus_number = as.factor(stimulus_number),
         arms = as.numeric(arms),
         spots = as.numeric(spots), 
         legs = as.numeric(legs),
         eyes = as.numeric(eyes), 
         color = as.numeric(color))

#Create three datasets shuffled by rows
set.seed(1993)
shuffled_data_1 = data[sample(1:nrow(data)), ]

set.seed(1997)
shuffled_data_2 = data[sample(1:nrow(data)), ]

set.seed(1999)
shuffled_data_3 = data[sample(1:nrow(data)), ]

#Combine shuffled datasets
experiment <- rbind(shuffled_data_1, shuffled_data_2, shuffled_data_3)

```


```{r}
#Defining similarity and distance

# Distance 
distance <- function(vect1, vect2, w) {
  return(sum(w * abs(vect1 - vect2)))
}

# Similarity
similarity <- function(distance, c) {
  return(exp(-c * distance))
}

```


**GCM**

```{r}
#Define model

gcm <- function(w, c, obs, cat_one, quiet = TRUE) {
  # create an empty list to save probability of saying "1" for each trial
  r <- c()
  
  ntrials <- nrow(obs)
  
  for (i in 1:ntrials) {
    # If quiet is FALSE, print every ten trials
    if (!quiet && i %% 10 == 0) {
      print(paste("i =", i))
    }
    # if this is the first trial, or there any category with no exemplars seen yet, set the choice to random
    if (i == 1 || sum(cat_one[1:(i - 1)]) == 0 || sum(cat_one[1:(i - 1)]) == (i - 1)) {
      r <- c(r, .5)
    } else {
      similarities <- c()
      # for each previously seen stimulus assess distance and similarity
      for (e in 1:(i - 1)) {
        sim <- similarity(distance(obs[i, ], obs[e, ], w), c)
        similarities <- c(similarities, sim)
      }
      # Calculate prob of saying "1" by dividing similarity to 1 by the sum of similarity to 1 and to 2
      numerator <- 0.5 * sum(similarities[cat_one[1:(i - 1)] == 1])
      denominator <- 0.5 * sum(similarities[cat_one[1:(i - 1)] == 1]) + 0.5 * sum(similarities[cat_one[1:(i - 1)] == 0])
      r <- c(r, numerator / denominator)
    }
  }

  return(rbinom(ntrials, 1, r))
}

```

```{r}
#Function for simulating responses

simulate_responses <- function(agent, w, c) {
    
    observations <- experiment %>%
        select(c("eyes", "legs", "spots", "arms", "color"))
    
    danger <- experiment$danger
    
    #create weights
    if (w == "equal") { #equal weights for all features
        weight <- rep(0.2, 5)
    } else if (w == "optimal") { #only weighting the relevant features (spots and eyes)
        weight <- c(0.5, 0, 0.5, 0, 0)
    }

    # simulate responses
    responses <- gcm(
        weight,
        c,
        observations,
        danger)
    
    tmp_simulated_responses <- experiment %>%
        mutate(
            trial = seq(nrow(experiment)),
            sim_response = responses,
            correct = ifelse(danger == sim_response, 1, 0),
            performance = cumsum(correct) / seq_along(correct),
            c = c,
            w = w,
            agent = agent
        )

    return(tmp_simulated_responses)
}

```


```{r}
#Simulate responses for ten agents
plan(multisession, workers = availableCores())

param_df <- dplyr::tibble(
    expand_grid(
        agent = 1:10,
        c = c(0.7, 1.2, 1.7), #sensitivity 
        w = c("equal", "optimal") #weights
    )
)

simulated_responses <- future_pmap_dfr(param_df,
    simulate_responses,
    .options = furrr_options(seed = TRUE)
)
```


**Subset and plot**
```{r}

df_simulated_responses <- simulated_responses %>% 
  subset(c == "0.7" & w == "optimal")

```

```{r}

ggplot(df_simulated_responses, aes(x = trial, y = performance, color = as.factor(agent))) +
  geom_line () +
  #facet_wrap(~ df_simulated_responses$agent) + 
  labs(x = "Trial", y = "Performance", color = "Agent")

```


**Fit Stan** 

```{r}
n_agents = 1

for (i in 1:n_agents) {
  d <- simulated_responses %>% subset(c == "1.7" & w == "optimal" & agent == 1)
  
  gcm_data <- list(
    ntrials = nrow(d),
    nfeatures = 5,
    cat_one = d$danger, # "true responses on a trial by trial basis"
    y = d$sim_response,
    obs = as.matrix(d[, c("eyes", "legs", "spots", "arms", "color")]),
    b = 0.5,
    w_prior_values = c(1, 1, 1, 1, 1),
    c_prior_values = c(0, 1)
  )
    
  mod_GCM <- cmdstan_model("gcm.stan", cpp_options = list(stan_threads = TRUE), stanc_options = list("O1"))
    
  samples <- mod_GCM$sample(
    data = gcm_data, # the data :-)
    seed = 123,  # a seed, so I always get the same results
    chains = 2,  # how many chains should I fit (to check whether they give the same results)                   ##NB!!! testing with 1 (normal 2)
    parallel_chains = 2, # how many of the chains can be run in parallel?
    threads_per_chain = 4, # distribute gradient estimations within chain across multiple cores                 ##NB!! testing with 4 (normal 2)
    iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
    iter_sampling = 2000, # total number of iterations
    refresh = 100,  # how often to show that iterations have been run
    max_treedepth = 20, # how many steps in the future to check to avoid u-turns
    adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
  )
  
  #Disabling scientific notation
  options(scipen=999)
    
  #extract summary 
  samples$summary()
  
  # assign function within loop
  #assign(paste0("weighted_summary_ID_", i), samples$summary())
}
```


```{r}

draws_df_1.7 <- as_draws_df(samples$draws())


draws_df_1.7 <- draws_df_1.7 %>% 
  rename (w_1 = "w[1]",
         w_prior_1 = "w_prior[1]")

draws_df_1.7 <- draws_df_1.7 %>% 
  rename (w_2 = "w[2]",
         w_prior_2 = "w_prior[2]")

#samples$summary()

ggplot(draws_df_1.7) +
  geom_density(aes(c), fill = "blue", alpha = 0.3) +
  geom_density(aes(c_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 1.7, linetype = "dashed", color = "black", size = 1.5) +
  xlab("C = 1.7") +
  ylab("Posterior Density") +
  theme_classic()


#samples$summary()

ggplot(draws_df_1.7) +
  geom_density(aes(w_1), fill = "blue", alpha = 0.3) +
  geom_density(aes(w_prior_1), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Weight 1 = 0.5") +
  ylab("Posterior Density") +
  ggtitle("C = 1.7") +
  xlim(0,1) +
  ylim(0,8) +
  theme_classic()


ggplot(draws_df_1.7) +
  geom_density(aes(w_2), fill = "blue", alpha = 0.3) +
  geom_density(aes(w_prior_2), fill = "red", alpha = 0.3) + 
  geom_vline(xintercept = 0, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Weight 2 = 0") +
  ylab("Posterior Density") +
  ggtitle("C = 1.7") +
  xlim(0, 1) +
  ylim(0, 8) +
  theme_classic()


ggplot(draws_df_1.7) +
  geom_density(aes(w_1), fill = "orange", alpha = 0.3) +
  geom_density(aes(w_2), fill = "green", alpha = 0.3) +
  geom_density(aes(w_prior_1), color = "red") +
  #geom_vline(xintercept = 0.2, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Weight 1 = 0.5 (orange), Weight 2 = 0 (green)") +
  ylab("Posterior Density") +
  ggtitle("C = 1.7") +
  xlim(0,1)+
  ylim(0,5)+
  theme_classic()

```






#Empirical data

```{r}
df <- read.delim("AlienData.txt", sep= ",")
```


```{r}
df <- df[!grepl("pt", df$stimulus), ]

# code columns for each feature in empiral data
df <- df %>% 
  mutate(eyes = str_sub(stimulus, 1, 1)) %>% 
  mutate(legs = str_sub(stimulus, 2, 2)) %>% 
  mutate(spots = str_sub(stimulus, 3, 3)) %>% 
  mutate(arms = str_sub(stimulus, 4, 4)) %>% 
  mutate(color = str_sub(stimulus, 5, 5)) %>% 
  filter(session == 1 & condition == 2)

df <- df %>%
  mutate_at(vars(-stimulus), as.numeric)

subjectlist <- unique(df$subject)


#Recoding to delete the nutritious dimension 
df <- df %>% 
  mutate(response_2 = ifelse(response == 1 | response == 2, 0, 1),
         category_2 = ifelse(category == 1 | category == 2, 0, 1), 
         correct_2 = ifelse(category == response, 1, 0)
         )


```


```{r}

for (i in 1:length(subjectlist)) {
  
  df_2 <- df %>% subset(subject == i)  
  
  gcm_data <- list(
    ntrials = nrow(df_2),
    nfeatures = 5,
    cat_one = df_2$danger, # "true responses on a trial by trial basis"
    y = df_2$response_2,
    obs = as.matrix(df_2[, c("eyes", "legs", "spots", "arms", "color")]),
    b = 0.5,
    c = 2.2,
    w_prior_values = c(1, 1, 1, 1, 1),
    c_prior_values = c(0, 1)
  )
    
  mod_GCM <- cmdstan_model("gcm.stan", cpp_options = list(stan_threads = TRUE), stanc_options = list("O1"))
    
  samples <- mod_GCM$sample(
    data = gcm_data, # the data :-)
    seed = 123,  # a seed, so I always get the same results
    chains = 2,  # how many chains should I fit (to check whether they give the same results)                   ##NB!!! testing with 1 (normal 2)
    parallel_chains = 2, # how many of the chains can be run in parallel?
    threads_per_chain = 4, # distribute gradient estimations within chain across multiple cores                 ##NB!! testing with 4 (normal 2)
    iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
    iter_sampling = 2000, # total number of iterations
    refresh = 100,  # how often to show that iterations have been run
    max_treedepth = 20, # how many steps in the future to check to avoid u-turns
    adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
  )
  
  #Disabling scientific notation
  options(scipen=999)
    
  #extract summary 
  samples$summary()
  
  # assign function within loop
  #assign(paste0("weighted_summary_ID_", i), samples$summary())
}
```





```{r}
df <- df[!grepl("pt", df$stimulus), ]

df_2 <- df %>% subset(subject == 1 & session == 1 & condition == 1)  
 
  gcm_data <- list(
    ntrials = nrow(df_2),
    nfeatures = 5,
    cat_one = df_2$danger, # "true responses on a trial by trial basis"
    y = df_2$sim_response,
    obs = as.matrix(df_2[, c("eyes", "legs", "spots", "arms", "color")]),
    b = 0.5,
    c = 2.2,
    w_prior_values = c(1, 1, 1, 1, 1),
    c_prior_values = c(0, 1)
  )
  
  
  
  gcm_data
```

